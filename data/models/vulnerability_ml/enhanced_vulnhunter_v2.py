#!/usr/bin/env python3
"""
ENHANCED VULNHUNTER V2 - Integration of All Training Data
Incorporates false positive detection, specialized models, and validation capabilities
"""

import joblib
import pandas as pd
import numpy as np
import json
import re
import os
from typing import Dict, List, Tuple, Any

class EnhancedVulnHunterV2:
    """
    Enhanced VulnHunter with integrated false positive detection,
    specialized vulnerability models, and comprehensive validation.
    """

    def __init__(self, base_model_dir=".", enhanced_model_dir="../enhanced_models"):
        self.base_model_dir = base_model_dir
        self.enhanced_model_dir = enhanced_model_dir
        self.load_all_models()
        self.load_false_positive_patterns()
        self.load_validation_data()

    def load_all_models(self):
        """Load base models, enhanced models, and false positive detectors."""
        self.models_loaded = {}

        # Load base VulnHunter models
        try:
            self.severity_model = joblib.load(f"{self.base_model_dir}/optimized_severity_model.pkl")
            self.scaler = joblib.load(f"{self.base_model_dir}/optimized_scaler.pkl")
            self.bounty_model = joblib.load(f"{self.base_model_dir}/bounty_model.pkl")
            self.feature_names = joblib.load(f"{self.base_model_dir}/optimized_features.pkl")
            self.models_loaded['base'] = True
            print("✅ Base VulnHunter models loaded")
        except Exception as e:
            print(f"⚠️ Base models error: {e}")
            self.models_loaded['base'] = False

        # Load false positive detector
        try:
            self.false_positive_detector = joblib.load("../models/false_positive_detector_20251013_141024.pkl")
            self.models_loaded['false_positive'] = True
            print("✅ False positive detector loaded")
        except Exception as e:
            print(f"⚠️ False positive detector error: {e}")
            self.models_loaded['false_positive'] = False

        # Load enhanced specialized models
        self.enhanced_models = {}
        enhanced_model_files = [
            "executables_enhanced_model.joblib",
            "http_requests_enhanced_model.joblib",
            "mobile_apps_enhanced_model.joblib",
            "open_source_code_enhanced_model.joblib",
            "smart_contracts_enhanced_model.joblib"
        ]

        for model_file in enhanced_model_files:
            try:
                model_path = f"{self.enhanced_model_dir}/{model_file}"
                if os.path.exists(model_path):
                    model_name = model_file.replace("_enhanced_model.joblib", "")
                    self.enhanced_models[model_name] = joblib.load(model_path)
                    print(f"✅ Enhanced {model_name} model loaded")
            except Exception as e:
                print(f"⚠️ Enhanced model {model_file} error: {e}")

    def load_false_positive_patterns(self):
        """Load false positive detection patterns from training data."""
        try:
            with open("../training/false_positive_training_20251013_140908.json", 'r') as f:
                self.false_positive_patterns = json.load(f)

            with open("../training/comprehensive_vulnhunter_case_study_report.json", 'r') as f:
                self.validation_report = json.load(f)

            print("✅ False positive patterns loaded")
        except Exception as e:
            print(f"⚠️ False positive patterns error: {e}")
            self.false_positive_patterns = {}
            self.validation_report = {}

    def load_validation_data(self):
        """Load Microsoft bounty and other validation data."""
        try:
            with open("../training/microsoft_bounty_training_20251013_142441.json", 'r') as f:
                self.bounty_validation_data = json.load(f)
            print("✅ Bounty validation data loaded")
        except Exception as e:
            print(f"⚠️ Bounty validation data error: {e}")
            self.bounty_validation_data = {}

    def detect_false_positive_patterns(self, description: str, location: str = "") -> Dict[str, Any]:
        """Detect false positive patterns in vulnerability claims."""
        fp_score = 0.0
        red_flags = []

        # Check for fabricated code patterns
        fabrication_patterns = [
            r'unsafe\s*\{\s*transmute\(',
            r'unsafe\s*\{\s*std::ptr::write\(',
            r'unsafe\s*\{\s*slice::from_raw_parts\(',
            r'exec\.Command\([^)]*user[^)]*\)',
            r'filepath\.Join\([^)]*\.\.[^)]*\)'
        ]

        for pattern in fabrication_patterns:
            if re.search(pattern, description):
                fp_score += 0.3
                red_flags.append(f"Potentially fabricated code pattern: {pattern}")

        # Check for impossible line references
        if location and re.search(r':(\d+)', location):
            line_num = int(re.search(r':(\d+)', location).group(1))
            if line_num > 2000:  # Suspiciously high line numbers
                fp_score += 0.4
                red_flags.append(f"Suspicious line number: {line_num}")

        # Check for inflated vulnerability counts
        vuln_count_patterns = [
            r'(\d+)\s*vulnerabilities',
            r'(\d+)\s*issues',
            r'(\d+)\s*findings'
        ]

        for pattern in vuln_count_patterns:
            match = re.search(pattern, description)
            if match and int(match.group(1)) > 100:
                fp_score += 0.5
                red_flags.append(f"Inflated vulnerability count: {match.group(1)}")

        # Check for artificial confidence indicators
        if 'confidence' in description.lower() and '98.' in description:
            fp_score += 0.3
            red_flags.append("Artificial confidence indicator detected")

        return {
            'false_positive_score': min(fp_score, 1.0),
            'red_flags': red_flags,
            'classification': 'HIGH_FP_RISK' if fp_score > 0.7 else 'MEDIUM_FP_RISK' if fp_score > 0.4 else 'LOW_FP_RISK'
        }

    def select_specialized_model(self, description: str) -> str:
        """Select the most appropriate specialized model based on content."""
        desc_lower = description.lower()

        # Smart contract related
        if any(term in desc_lower for term in ['solidity', 'smart contract', 'ethereum', 'web3', 'defi']):
            return 'smart_contracts'

        # Mobile app related
        if any(term in desc_lower for term in ['android', 'ios', 'mobile', 'app store', 'apk']):
            return 'mobile_apps'

        # HTTP/Web related
        if any(term in desc_lower for term in ['http', 'web', 'api', 'endpoint', 'cors', 'xss', 'csrf']):
            return 'http_requests'

        # Executable/Binary related
        if any(term in desc_lower for term in ['executable', 'binary', 'malware', 'pe file', 'elf']):
            return 'executables'

        # Default to open source code
        return 'open_source_code'

    def extract_enhanced_features(self, description: str, location: str = "") -> np.ndarray:
        """Extract enhanced features for ML prediction."""
        features = {}
        desc_lower = description.lower()

        # Basic text features
        features['desc_length'] = len(description)
        features['word_count'] = len(description.split())
        features['location_provided'] = 1 if location else 0

        # Security severity indicators
        critical_terms = ['remote code execution', 'arbitrary code', 'buffer overflow', 'sql injection']
        high_terms = ['path traversal', 'authentication bypass', 'privilege escalation']
        medium_terms = ['information disclosure', 'cors', 'csrf', 'xss']

        features['critical_indicators'] = sum(1 for term in critical_terms if term in desc_lower)
        features['high_indicators'] = sum(1 for term in high_terms if term in desc_lower)
        features['medium_indicators'] = sum(1 for term in medium_terms if term in desc_lower)

        # Code-specific features
        features['code_patterns'] = len(re.findall(r'[a-zA-Z_][a-zA-Z0-9_]*\(', description))
        features['file_references'] = len(re.findall(r'\w+\.\w+:\d+', description))
        features['cve_references'] = len(re.findall(r'CVE-\d{4}-\d{4,}', description))

        # Convert to feature vector
        if hasattr(self, 'feature_names'):
            feature_vector = np.zeros(len(self.feature_names))
            for i, feature_name in enumerate(self.feature_names):
                if feature_name in features:
                    feature_vector[i] = features[feature_name]
            return feature_vector.reshape(1, -1)
        else:
            return np.array(list(features.values())).reshape(1, -1)

    def predict_comprehensive(self, description: str, location: str = "", validate: bool = True) -> Dict[str, Any]:
        """Comprehensive vulnerability prediction with false positive detection."""

        # Step 1: False positive detection
        if validate:
            fp_analysis = self.detect_false_positive_patterns(description, location)
            if fp_analysis['false_positive_score'] > 0.7:
                return {
                    'severity': 'INVALID_CLAIM',
                    'confidence': 0.0,
                    'estimated_bounty': 0,
                    'bounty_currency': 'USD',
                    'false_positive_analysis': fp_analysis,
                    'validation_status': 'FAILED_FP_CHECK',
                    'recommendation': 'Claim appears to be false positive based on training patterns'
                }

        # Step 2: Select specialized model
        specialized_model_type = self.select_specialized_model(description)

        # Step 3: Extract features
        features = self.extract_enhanced_features(description, location)

        # Step 4: Predict using appropriate models
        result = {}

        if self.models_loaded.get('base', False):
            try:
                # Scale features if scaler available
                if hasattr(self, 'scaler'):
                    features_scaled = self.scaler.transform(features)
                else:
                    features_scaled = features

                # Severity prediction
                severity_pred = self.severity_model.predict(features_scaled)[0]
                severity_prob = self.severity_model.predict_proba(features_scaled)[0]

                # Map to human-readable severity
                severity_map = {0: 'Low', 1: 'Medium', 2: 'High', 3: 'Critical'}
                result['severity'] = severity_map.get(severity_pred, 'Medium')
                result['confidence'] = float(np.max(severity_prob))

                # Bounty prediction
                if hasattr(self, 'bounty_model'):
                    bounty_pred = self.bounty_model.predict(features_scaled)[0]
                    result['estimated_bounty'] = max(int(bounty_pred), 100)
                else:
                    # Fallback bounty estimation
                    bounty_map = {'Critical': 5000, 'High': 2000, 'Medium': 800, 'Low': 200}
                    result['estimated_bounty'] = bounty_map.get(result['severity'], 500)

                result['bounty_currency'] = 'USD'

            except Exception as e:
                print(f"Prediction error: {e}")
                result = {
                    'severity': 'Medium',
                    'confidence': 0.5,
                    'estimated_bounty': 500,
                    'bounty_currency': 'USD'
                }

        # Step 5: Enhanced model consultation
        if specialized_model_type in self.enhanced_models:
            try:
                enhanced_pred = self.enhanced_models[specialized_model_type].predict(features)[0]
                result['enhanced_model_used'] = specialized_model_type
                result['enhanced_prediction'] = enhanced_pred
            except Exception as e:
                print(f"Enhanced model error: {e}")

        # Step 6: Add validation context
        if validate and hasattr(self, 'validation_report'):
            result['validation_context'] = {
                'training_validated_analyses': self.validation_report.get('executive_summary', {}).get('total_analyses_validated', 0),
                'known_false_positive_rate': self.validation_report.get('executive_summary', {}).get('overall_false_positive_rate', 0.0),
                'model_version': 'Enhanced VulnHunter V2'
            }

        return result

def test_enhanced_vulnhunter():
    """Test the enhanced VulnHunter model."""
    print("🔍 Testing Enhanced VulnHunter V2...")

    predictor = EnhancedVulnHunterV2()

    # Test cases including known false positive patterns
    test_cases = [
        {
            'description': 'HTTP server without authentication on API endpoints',
            'location': 'server/routes.go:1456',
            'expected': 'Valid concern'
        },
        {
            'description': 'unsafe { transmute(raw_ptr) } found in oauth.rs:715',
            'location': 'oauth.rs:715',
            'expected': 'False positive (fabricated pattern)'
        },
        {
            'description': 'Found 2553 dangerous vulnerabilities with 98.8% confidence',
            'location': '',
            'expected': 'False positive (inflated count)'
        },
        {
            'description': 'Path traversal in file upload without validation',
            'location': 'upload.go:45',
            'expected': 'Valid concern'
        }
    ]

    for i, test_case in enumerate(test_cases, 1):
        print(f"\n📝 Test Case {i}: {test_case['expected']}")
        print(f"Description: {test_case['description'][:60]}...")

        result = predictor.predict_comprehensive(
            test_case['description'],
            test_case['location']
        )

        print(f"Result: {result['severity']} | Confidence: {result.get('confidence', 0):.2f}")
        if 'false_positive_analysis' in result:
            print(f"FP Score: {result['false_positive_analysis']['false_positive_score']:.2f}")
            print(f"Classification: {result['false_positive_analysis']['classification']}")

if __name__ == "__main__":
    test_enhanced_vulnhunter()