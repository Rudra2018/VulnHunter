#!/usr/bin/env python3
"""
Vulnerability Validation and Verification Engine
Confirms vulnerabilities are real and not false positives
"""

import re
import subprocess
import tempfile
from typing import Dict, List, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass, asdict
import logging
from datetime import datetime

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

from core.comprehensive_vulnerability_tester import (
    VulnerabilityFinding, VulnerabilityType, Severity
)

# Optional FP engine import
try:
    from core.enhanced_fp_engine import HackerOneFPEngine
    FP_ENGINE_AVAILABLE = True
except ImportError:
    FP_ENGINE_AVAILABLE = False
    logger.warning("FP engine not available (missing dependencies)")


@dataclass
class ValidationResult:
    """Result of vulnerability validation"""
    finding_id: str
    is_valid: bool
    confidence: float
    validation_method: str
    verification_steps_completed: List[str]
    proof_of_concept_result: Optional[str]
    false_positive_reason: Optional[str]
    additional_evidence: Optional[Dict]
    validated_at: str


class VulnerabilityValidator:
    """
    Validates and verifies vulnerability findings
    """

    def __init__(self):
        self.fp_engine = None
        if FP_ENGINE_AVAILABLE:
            try:
                self.fp_engine = HackerOneFPEngine()
            except Exception as e:
                logger.warning(f"FP engine initialization failed: {e}")

        self.validation_results = []

    def validate_sql_injection(self, finding: VulnerabilityFinding) -> ValidationResult:
        """
        Validate SQL injection vulnerability
        """
        logger.info(f"Validating SQL injection: {finding.id}")

        code = finding.evidence.code_snippet
        is_valid = True
        confidence = 0.0
        steps_completed = []
        poc_result = None
        fp_reason = None
        additional_evidence = {}

        # Step 1: Check for parameterized queries (safe pattern)
        if re.search(r'\?|prepare|bind_param|\$\d+', code):
            is_valid = False
            confidence = 0.9
            fp_reason = "Uses parameterized queries - safe from SQL injection"
            steps_completed.append("✓ Checked for parameterized queries - FOUND")
        else:
            steps_completed.append("✓ Checked for parameterized queries - NOT FOUND")
            confidence += 0.3

        # Step 2: Check for string concatenation/formatting
        if re.search(r'["\'].*?["\'][\s]*[\+\%]|f["\'].*?\{', code):
            steps_completed.append("✓ Detected string concatenation in SQL query")
            confidence += 0.3
            additional_evidence['concatenation'] = True
        else:
            steps_completed.append("✗ No string concatenation detected")

        # Step 3: Check for user input flow
        user_input_patterns = [
            'request', 'params', 'input', 'user', 'form', 'query',
            'args', 'data', 'body', 'req.', 'flask.request'
        ]

        has_user_input = any(pattern in code.lower() for pattern in user_input_patterns)
        if has_user_input:
            steps_completed.append("✓ User input flows into SQL query")
            confidence += 0.2
            additional_evidence['user_input'] = True
        else:
            steps_completed.append("⚠ Could not confirm user input flow (may need manual check)")
            confidence += 0.1

        # Step 4: Check with FP engine
        if self.fp_engine and is_valid:
            try:
                fp_result = self.fp_engine.predict(
                    code=code,
                    report_text="",
                    model_prediction=1,
                    model_confidence=confidence
                )

                if fp_result['is_false_positive']:
                    is_valid = False
                    confidence = fp_result['confidence']
                    fp_reason = fp_result['reasoning']
                    steps_completed.append(f"✓ FP Engine check: {fp_reason}")
                else:
                    steps_completed.append("✓ FP Engine confirmed vulnerability")
                    confidence = max(confidence, fp_result['confidence'])
            except Exception as e:
                steps_completed.append(f"⚠ FP Engine check failed: {e}")

        # Step 5: Generate proof of concept
        if is_valid:
            poc_result = self._generate_sql_injection_poc(finding)
            if poc_result:
                steps_completed.append("✓ Generated proof of concept")
                additional_evidence['poc'] = poc_result
            else:
                steps_completed.append("⚠ Could not generate automated PoC")

        # Final confidence adjustment
        if not is_valid:
            confidence = 1.0 - confidence  # Invert for FP

        return ValidationResult(
            finding_id=finding.id,
            is_valid=is_valid,
            confidence=confidence,
            validation_method="Automated + Pattern Analysis",
            verification_steps_completed=steps_completed,
            proof_of_concept_result=poc_result,
            false_positive_reason=fp_reason,
            additional_evidence=additional_evidence,
            validated_at=datetime.now().isoformat()
        )

    def validate_xss(self, finding: VulnerabilityFinding) -> ValidationResult:
        """
        Validate XSS vulnerability
        """
        logger.info(f"Validating XSS: {finding.id}")

        code = finding.evidence.code_snippet
        is_valid = True
        confidence = 0.0
        steps_completed = []
        poc_result = None
        fp_reason = None
        additional_evidence = {}

        # Step 1: Check for sanitization
        sanitizers = ['sanitize', 'escape', 'DOMPurify', 'textContent', 'encodeURIComponent']
        has_sanitization = any(sanitizer in code for sanitizer in sanitizers)

        if has_sanitization:
            is_valid = False
            confidence = 0.85
            fp_reason = "Output is sanitized - protected against XSS"
            steps_completed.append("✓ Sanitization detected - SAFE")
        else:
            steps_completed.append("✓ No sanitization detected")
            confidence += 0.3

        # Step 2: Check for dangerous sinks
        dangerous_sinks = ['innerHTML', 'document.write', 'eval', 'v-html', 'dangerouslySetInnerHTML']
        has_dangerous_sink = any(sink in code for sink in dangerous_sinks)

        if has_dangerous_sink:
            steps_completed.append("✓ Dangerous sink detected (innerHTML/document.write/etc)")
            confidence += 0.3
            additional_evidence['dangerous_sink'] = True
        else:
            steps_completed.append("✗ No dangerous sink found")

        # Step 3: Check for user input
        user_input_patterns = ['req', 'request', 'params', 'input', 'user', 'props', 'state']
        has_user_input = any(pattern in code.lower() for pattern in user_input_patterns)

        if has_user_input:
            steps_completed.append("✓ User input flows to output")
            confidence += 0.2
            additional_evidence['user_input'] = True
        else:
            steps_completed.append("⚠ Could not confirm user input flow")
            confidence += 0.1

        # Step 4: Check for CSP (Content Security Policy)
        # This would require checking HTTP headers, which we can't do in static analysis
        steps_completed.append("⚠ CSP check requires runtime analysis")

        # Step 5: Generate PoC
        if is_valid:
            poc_result = self._generate_xss_poc(finding)
            if poc_result:
                steps_completed.append("✓ Generated XSS proof of concept")
                additional_evidence['poc'] = poc_result
            else:
                steps_completed.append("⚠ Could not generate automated PoC")

        return ValidationResult(
            finding_id=finding.id,
            is_valid=is_valid,
            confidence=confidence,
            validation_method="Static Analysis + Pattern Matching",
            verification_steps_completed=steps_completed,
            proof_of_concept_result=poc_result,
            false_positive_reason=fp_reason,
            additional_evidence=additional_evidence,
            validated_at=datetime.now().isoformat()
        )

    def validate_command_injection(self, finding: VulnerabilityFinding) -> ValidationResult:
        """
        Validate command injection vulnerability
        """
        logger.info(f"Validating command injection: {finding.id}")

        code = finding.evidence.code_snippet
        is_valid = True
        confidence = 0.0
        steps_completed = []
        poc_result = None
        fp_reason = None
        additional_evidence = {}

        # Step 1: Check for shell=False (safe)
        if 'shell=False' in code or 'shell = False' in code:
            is_valid = False
            confidence = 0.9
            fp_reason = "subprocess with shell=False - safe from command injection"
            steps_completed.append("✓ shell=False detected - SAFE")
        else:
            steps_completed.append("✓ No shell=False protection")
            confidence += 0.3

        # Step 2: Check for dangerous functions
        dangerous_functions = ['os.system', 'subprocess.call', 'eval', 'exec', 'shell=True']
        has_dangerous = any(func in code for func in dangerous_functions)

        if has_dangerous:
            steps_completed.append("✓ Dangerous function detected")
            confidence += 0.3
            additional_evidence['dangerous_function'] = True
        else:
            steps_completed.append("✗ No dangerous function found")

        # Step 3: Check for input validation
        validation_patterns = ['shlex.quote', 'escape', 'whitelist', 'allowed_commands']
        has_validation = any(pattern in code for pattern in validation_patterns)

        if has_validation:
            is_valid = False
            confidence = 0.8
            fp_reason = "Input validation detected"
            steps_completed.append("✓ Input validation found - may be safe")
        else:
            steps_completed.append("✓ No input validation")
            confidence += 0.2

        # Step 4: Check for user input
        user_input_patterns = ['request', 'input', 'user', 'param']
        has_user_input = any(pattern in code.lower() for pattern in user_input_patterns)

        if has_user_input:
            steps_completed.append("✓ User input flows to command")
            confidence += 0.2
            additional_evidence['user_input'] = True
        else:
            steps_completed.append("⚠ Could not confirm user input")
            confidence += 0.1

        # Step 5: Generate PoC
        if is_valid:
            poc_result = self._generate_command_injection_poc(finding)
            if poc_result:
                steps_completed.append("✓ Generated command injection PoC")
                additional_evidence['poc'] = poc_result

        return ValidationResult(
            finding_id=finding.id,
            is_valid=is_valid,
            confidence=confidence,
            validation_method="Static Analysis + Function Detection",
            verification_steps_completed=steps_completed,
            proof_of_concept_result=poc_result,
            false_positive_reason=fp_reason,
            additional_evidence=additional_evidence,
            validated_at=datetime.now().isoformat()
        )

    def validate_path_traversal(self, finding: VulnerabilityFinding) -> ValidationResult:
        """
        Validate path traversal vulnerability
        """
        logger.info(f"Validating path traversal: {finding.id}")

        code = finding.evidence.code_snippet
        is_valid = True
        confidence = 0.0
        steps_completed = []
        poc_result = None
        fp_reason = None
        additional_evidence = {}

        # Step 1: Check for path validation
        safe_functions = ['basename', 'safe_join', 'realpath', 'normpath', 'abspath']
        has_validation = any(func in code for func in safe_functions)

        if has_validation:
            is_valid = False
            confidence = 0.85
            fp_reason = "Path validation detected (basename/safe_join/etc)"
            steps_completed.append("✓ Path validation found - SAFE")
        else:
            steps_completed.append("✓ No path validation")
            confidence += 0.3

        # Step 2: Check for file operations
        file_ops = ['open', 'read', 'readFile', 'File.read']
        has_file_op = any(op in code for op in file_ops)

        if has_file_op:
            steps_completed.append("✓ File operation detected")
            confidence += 0.2
            additional_evidence['file_operation'] = True
        else:
            steps_completed.append("✗ No file operation found")

        # Step 3: Check for user input in path
        user_input_patterns = ['request', 'params', 'input', 'user', 'filename']
        has_user_input = any(pattern in code.lower() for pattern in user_input_patterns)

        if has_user_input:
            steps_completed.append("✓ User input in file path")
            confidence += 0.3
            additional_evidence['user_input'] = True
        else:
            steps_completed.append("⚠ Could not confirm user input")
            confidence += 0.1

        # Step 4: Check for path concatenation
        if '+' in code or 'join' in code:
            steps_completed.append("✓ Path concatenation detected")
            confidence += 0.2
        else:
            steps_completed.append("✗ No obvious path concatenation")

        # Step 5: Generate PoC
        if is_valid:
            poc_result = self._generate_path_traversal_poc(finding)
            if poc_result:
                steps_completed.append("✓ Generated path traversal PoC")
                additional_evidence['poc'] = poc_result

        return ValidationResult(
            finding_id=finding.id,
            is_valid=is_valid,
            confidence=confidence,
            validation_method="Static Analysis + Path Validation Check",
            verification_steps_completed=steps_completed,
            proof_of_concept_result=poc_result,
            false_positive_reason=fp_reason,
            additional_evidence=additional_evidence,
            validated_at=datetime.now().isoformat()
        )

    def validate_finding(self, finding: VulnerabilityFinding) -> ValidationResult:
        """
        Validate a vulnerability finding based on its type
        """
        if finding.type == VulnerabilityType.SQL_INJECTION:
            return self.validate_sql_injection(finding)
        elif finding.type == VulnerabilityType.XSS:
            return self.validate_xss(finding)
        elif finding.type == VulnerabilityType.COMMAND_INJECTION:
            return self.validate_command_injection(finding)
        elif finding.type == VulnerabilityType.PATH_TRAVERSAL:
            return self.validate_path_traversal(finding)
        else:
            # Generic validation
            return ValidationResult(
                finding_id=finding.id,
                is_valid=True,
                confidence=0.5,
                validation_method="Manual review required",
                verification_steps_completed=["⚠ Automated validation not available for this type"],
                proof_of_concept_result=None,
                false_positive_reason=None,
                additional_evidence={},
                validated_at=datetime.now().isoformat()
            )

    def validate_all(self, findings: List[VulnerabilityFinding]) -> List[ValidationResult]:
        """
        Validate all findings
        """
        logger.info(f"Validating {len(findings)} findings...")

        results = []
        for finding in findings:
            result = self.validate_finding(finding)
            results.append(result)
            self.validation_results.append(result)

            status = "✓ VALID" if result.is_valid else "✗ FALSE POSITIVE"
            logger.info(f"{finding.id}: {status} (confidence: {result.confidence:.1%})")

        # Summary
        valid_count = sum(1 for r in results if r.is_valid)
        fp_count = len(results) - valid_count

        logger.info(f"\nValidation Summary:")
        logger.info(f"  Valid vulnerabilities: {valid_count}")
        logger.info(f"  False positives: {fp_count}")
        logger.info(f"  FP rate: {fp_count/len(results):.1%}")

        return results

    def _generate_sql_injection_poc(self, finding: VulnerabilityFinding) -> Optional[str]:
        """Generate SQL injection proof of concept"""
        payloads = [
            "' OR '1'='1",
            "admin'--",
            "' UNION SELECT NULL--",
            "'; DROP TABLE users--"
        ]

        poc = f"""# SQL Injection Proof of Concept
# Target: {finding.affected_component}
# Line: {finding.evidence.line_numbers[0]}

## Test Payloads:
"""
        for i, payload in enumerate(payloads, 1):
            poc += f"{i}. {payload}\n"

        poc += """
## Expected Behavior:
- Payload 1: Should bypass authentication
- Payload 2: Comment-based injection
- Payload 3: Union-based data extraction
- Payload 4: Destructive (DO NOT USE in production)

## Verification Steps:
1. Intercept the request with Burp Suite
2. Replace user input with test payload
3. Observe if SQL logic is altered
4. Use sqlmap for automated testing: sqlmap -u "URL" -p "PARAM"
"""
        return poc

    def _generate_xss_poc(self, finding: VulnerabilityFinding) -> Optional[str]:
        """Generate XSS proof of concept"""
        payloads = [
            "<script>alert('XSS')</script>",
            "<img src=x onerror=alert('XSS')>",
            "<svg/onload=alert('XSS')>",
            "javascript:alert('XSS')"
        ]

        poc = f"""# XSS Proof of Concept
# Target: {finding.affected_component}
# Line: {finding.evidence.line_numbers[0]}

## Test Payloads:
"""
        for i, payload in enumerate(payloads, 1):
            poc += f"{i}. {payload}\n"

        poc += """
## Expected Behavior:
- Alert box should appear in browser
- JavaScript should execute in victim's context

## Verification Steps:
1. Inject payload into vulnerable parameter
2. Submit and observe if JavaScript executes
3. Check browser console for errors
4. Test with different encodings if blocked
"""
        return poc

    def _generate_command_injection_poc(self, finding: VulnerabilityFinding) -> Optional[str]:
        """Generate command injection proof of concept"""
        payloads = [
            "; whoami",
            "| whoami",
            "$(whoami)",
            "`whoami`",
            "&& whoami"
        ]

        poc = f"""# Command Injection Proof of Concept
# Target: {finding.affected_component}
# Line: {finding.evidence.line_numbers[0]}

## Test Payloads:
"""
        for i, payload in enumerate(payloads, 1):
            poc += f"{i}. test{payload}\n"

        poc += """
## Expected Behavior:
- Additional command should execute on server
- Output should include results of injected command

## Verification Steps:
1. Inject payload into user input field
2. Check application response for command output
3. Monitor server logs for command execution
4. Use safe commands only (whoami, pwd, ls)

⚠️ WARNING: Do not test destructive commands
"""
        return poc

    def _generate_path_traversal_poc(self, finding: VulnerabilityFinding) -> Optional[str]:
        """Generate path traversal proof of concept"""
        payloads = [
            "../../etc/passwd",
            "..%2F..%2Fetc%2Fpasswd",
            "....//....//etc/passwd",
            "..\\..\\windows\\win.ini"
        ]

        poc = f"""# Path Traversal Proof of Concept
# Target: {finding.affected_component}
# Line: {finding.evidence.line_numbers[0]}

## Test Payloads:
"""
        for i, payload in enumerate(payloads, 1):
            poc += f"{i}. {payload}\n"

        poc += """
## Expected Behavior:
- Application should return contents of system files
- /etc/passwd or win.ini contents visible

## Verification Steps:
1. Replace filename parameter with payload
2. Observe if file contents are returned
3. Try different encoding variations
4. Test for different OS (Linux vs Windows)

⚠️ Only read non-sensitive files for testing
"""
        return poc


if __name__ == "__main__":
    # Example usage
    from core.comprehensive_vulnerability_tester import ComprehensiveVulnerabilityTester

    logger.info("Vulnerability Validation Engine\n")

    # Run scanner
    tester = ComprehensiveVulnerabilityTester(".")
    findings = tester.comprehensive_scan(file_extensions=['.py'])

    if findings:
        # Validate findings
        validator = VulnerabilityValidator()
        validation_results = validator.validate_all(findings)

        # Show validated vulnerabilities only
        valid_findings = [
            (f, r) for f, r in zip(findings, validation_results)
            if r.is_valid and r.confidence > 0.7
        ]

        logger.info(f"\n{'='*80}")
        logger.info(f"VALIDATED VULNERABILITIES (Confidence > 70%)")
        logger.info(f"{'='*80}\n")

        for finding, result in valid_findings[:3]:
            logger.info(f"ID: {finding.id}")
            logger.info(f"Title: {finding.title}")
            logger.info(f"Confidence: {result.confidence:.1%}")
            logger.info(f"Validation Steps:")
            for step in result.verification_steps_completed:
                logger.info(f"  {step}")
            logger.info(f"{'─'*80}\n")
    else:
        logger.info("No vulnerabilities found to validate")
