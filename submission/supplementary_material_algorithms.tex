\documentclass[journal]{IEEEtran}

% Required packages
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{url}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{array}

% Math symbols and theorems
\usepackage{amsthm}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}

% Algorithm package
\usepackage[ruled,vlined]{algorithm2e}

\begin{document}

\title{Supplementary Material: Algorithm Implementation Details and Complexity Analysis}

\author{Ankit Thakur}

\markboth{IEEE TDSC Supplementary Material}%
{Thakur: Supplementary Material - Algorithm Details}

\maketitle

\section{Detailed Algorithm Implementations}

This supplementary material provides comprehensive implementation details for all algorithms presented in the main paper, including complexity analysis, convergence proofs, and implementation considerations.

\subsection{Game-Theoretic Nash Equilibrium Algorithm}

\subsubsection{Complete Algorithm Implementation}

\begin{algorithm}[H]
\caption{Complete Nash Equilibrium Computation}
\label{alg:nash_complete}
\begin{algorithmic}[1]
\REQUIRE Utility functions $(u_R, u_P, u_A)$, convergence threshold $\epsilon = 10^{-6}$
\REQUIRE Initial strategies $(s_R^0, s_P^0, s_A^0)$, maximum iterations $T_{max} = 1000$
\ENSURE Nash equilibrium strategies $(s_R^*, s_P^*, s_A^*)$, convergence flag
\STATE Initialize: $t \leftarrow 0$, $\text{converged} \leftarrow \text{false}$
\STATE $\text{history} \leftarrow [(s_R^0, s_P^0, s_A^0)]$
\WHILE{$t < T_{max}$ and not converged}
    \STATE // Researcher best response
    \STATE $s_R^{t+1} \leftarrow \arg\max_{s_R \in [0,1]} u_R(s_R, s_P^t, s_A^t)$
    \STATE // Program best response
    \STATE $s_P^{t+1} \leftarrow \arg\max_{s_P \in \mathbb{R}_+} u_P(s_R^{t+1}, s_P, s_A^t)$
    \STATE // Attacker best response
    \STATE $s_A^{t+1} \leftarrow \arg\max_{s_A \in [0,1]} u_A(s_R^{t+1}, s_P^{t+1}, s_A)$
    \STATE // Check convergence
    \STATE $\Delta \leftarrow \|(s_R^{t+1}, s_P^{t+1}, s_A^{t+1}) - (s_R^t, s_P^t, s_A^t)\|_2$
    \IF{$\Delta < \epsilon$}
        \STATE $\text{converged} \leftarrow \text{true}$
    \ENDIF
    \STATE $\text{history}.\text{append}((s_R^{t+1}, s_P^{t+1}, s_A^{t+1}))$
    \STATE $t \leftarrow t + 1$
\ENDWHILE
\RETURN $(s_R^{t}, s_P^{t}, s_A^{t})$, converged, history
\end{algorithmic}
\end{algorithm}

\subsubsection{Utility Function Definitions}

The utility functions are defined as follows:

\textbf{Researcher Utility:}
$$u_R(s_R, s_P, s_A) = s_R \cdot s_P \cdot (1 - s_A) - c_R \cdot s_R^2$$

where $c_R > 0$ is the cost coefficient for researcher effort.

\textbf{Program Utility:}
$$u_P(s_R, s_P, s_A) = \alpha \cdot s_R \cdot (1 - s_A) - s_P - \beta \cdot s_A$$

where $\alpha > 0$ represents the value of vulnerability discovery and $\beta > 0$ represents the cost of successful attacks.

\textbf{Attacker Utility:}
$$u_A(s_R, s_P, s_A) = \gamma \cdot s_A \cdot (1 - s_R) - c_A \cdot s_A^2$$

where $\gamma > 0$ represents the value of successful attacks and $c_A > 0$ is the cost coefficient.

\subsubsection{Convergence Analysis}

\begin{theorem}[Convergence Rate]
Under Lipschitz continuity conditions with constant $L$, the iterative algorithm converges with rate:
$$\|(s^{t+1} - s^*)\| \leq \rho^t \|(s^0 - s^*)\|$$
where $\rho = \frac{L}{1+L} < 1$ is the contraction factor.
\end{theorem}

\begin{proof}
The proof follows from the contraction mapping theorem. Given Lipschitz continuous utility functions, the best response mapping becomes a contraction with factor $\rho$, ensuring geometric convergence.
\end{proof}

\subsection{Information-Theoretic Scoring Algorithm}

\subsubsection{Complete Implementation}

\begin{algorithm}[H]
\caption{Complete Information-Theoretic Analysis}
\label{alg:info_complete}
\begin{algorithmic}[1]
\REQUIRE Dataset $\mathcal{D} = \{(x_i, y_i)\}_{i=1}^n$, feature names $F = \{f_1, \ldots, f_k\}$
\ENSURE Entropy scores, mutual information matrix, theoretical bounds
\STATE // Discretize continuous features
\FOR{each feature $f_j \in F$}
    \STATE $x_j \leftarrow \text{quantile\_discretize}(x_j, \text{bins}=10)$
\ENDFOR
\STATE // Compute individual entropies
\STATE $H\_scores \leftarrow \{\}$
\FOR{each feature $f_j \in F$}
    \STATE $p_j \leftarrow \text{compute\_distribution}(x_j)$
    \STATE $H(X_j) \leftarrow -\sum_k p_{j,k} \log_2 p_{j,k}$
    \STATE $H\_scores[f_j] \leftarrow H(X_j)$
\ENDFOR
\STATE // Compute target entropy
\STATE $p_y \leftarrow \text{compute\_distribution}(y)$
\STATE $H(Y) \leftarrow -\sum_k p_{y,k} \log_2 p_{y,k}$
\STATE // Compute joint entropies and mutual information
\STATE $MI\_matrix \leftarrow \text{zeros}(k, 1)$
\FOR{each feature $f_j \in F$}
    \STATE $p_{xy} \leftarrow \text{compute\_joint\_distribution}(x_j, y)$
    \STATE $H(X_j, Y) \leftarrow -\sum_{x,y} p_{xy}(x,y) \log_2 p_{xy}(x,y)$
    \STATE $I(X_j; Y) \leftarrow H(X_j) + H(Y) - H(X_j, Y)$
    \STATE $MI\_matrix[j] \leftarrow I(X_j; Y)$
\ENDFOR
\STATE // Compute theoretical bounds
\STATE $|\mathcal{Y}| \leftarrow \text{number\_of\_classes}(y)$
\STATE $I_{max} \leftarrow \max_j I(X_j; Y)$
\STATE $P_{e,min} \leftarrow \frac{H(Y) - I_{max} - 1}{\log_2 |\mathcal{Y}|}$
\STATE $\text{sample\_complexity} \leftarrow \frac{H(Y) + \log(1/\delta)}{\epsilon^2}$
\RETURN $H\_scores$, $MI\_matrix$, $P_{e,min}$, sample\_complexity
\end{algorithmic}
\end{algorithm}

\subsubsection{Information-Theoretic Bounds}

\begin{lemma}[Mutual Information Bound]
For any feature $X_j$ and target $Y$:
$$0 \leq I(X_j; Y) \leq \min(H(X_j), H(Y))$$
\end{lemma}

\begin{lemma}[Data Processing Inequality]
If $X_j \rightarrow X_j' \rightarrow Y$ forms a Markov chain, then:
$$I(X_j; Y) \geq I(X_j'; Y)$$
\end{lemma}

\subsection{Quantum-Inspired Uncertainty Quantification}

\subsubsection{Complete Quantum Encoding Algorithm}

\begin{algorithm}[H]
\caption{Complete Quantum State Encoding}
\label{alg:quantum_complete}
\begin{algorithmic}[1]
\require Vulnerability features $x \in \mathbb{R}^d$, qubits $k$, encoding method
\ensure Quantum state $|\psi\rangle$, Von Neumann entropy $S(\rho)$, Fisher information
\STATE // Normalize input features
\STATE $x' \leftarrow \frac{x - \mu}{\sigma}$ where $\mu, \sigma$ are mean and std
\STATE $x'' \leftarrow \tanh(x')$ // Map to [-1, 1]
\STATE // Generate quantum amplitudes
\STATE $N \leftarrow 2^k$ // Hilbert space dimension
\STATE $\alpha \leftarrow \text{zeros}(N)$
\FOR{$i = 0$ to $N-1$}
    \STATE $\text{binary} \leftarrow \text{int\_to\_binary}(i, k)$
    \STATE $\text{weight} \leftarrow \sum_{j=1}^{\min(d,k)} x''_j \cdot \text{binary}_j$
    \STATE $\alpha_i \leftarrow \exp(i \cdot \text{weight})$ // Complex amplitude
\ENDFOR
\STATE // Normalize to unit vector
\STATE $\alpha \leftarrow \frac{\alpha}{\|\alpha\|_2}$
\STATE $|\psi\rangle \leftarrow \sum_{i=0}^{N-1} \alpha_i |i\rangle$
\STATE // Construct density matrix
\STATE $\rho \leftarrow |\psi\rangle\langle\psi|$
\STATE // Compute Von Neumann entropy
\STATE $\text{eigenvals} \leftarrow \text{eigenvalues}(\rho)$
\STATE $S(\rho) \leftarrow -\sum_i \lambda_i \log_2 \lambda_i$ where $\lambda_i > 0$
\STATE // Compute Quantum Fisher Information
\STATE $F_Q \leftarrow 4 \sum_i \frac{|\langle i|\partial_\theta \psi\rangle|^2}{1 + \delta_{i,j}}$
\RETURN $|\psi\rangle$, $S(\rho)$, $F_Q$
\end{algorithmic}
\end{algorithm}

\subsubsection{Quantum Information Measures}

\begin{definition}[Quantum Fisher Information]
For a quantum state $|\psi(\theta)\rangle$ parametrized by $\theta$:
$$F_Q(\theta) = 4 \sum_{n} \frac{|\langle n|\partial_\theta \psi(\theta)\rangle|^2}{1 + \delta_{n,\psi}}$$
where $|n\rangle$ are eigenstate of the Hamiltonian.
\end{definition}

\begin{theorem}[Quantum Cram√©r-Rao Bound]
For any unbiased estimator $\hat{\theta}$ of parameter $\theta$:
$$\text{Var}(\hat{\theta}) \geq \frac{1}{F_Q(\theta)}$$
\end{theorem}

\subsection{Adversarial Robustness Certification}

\subsubsection{Complete Robustness Algorithm}

\begin{algorithm}[H]
\caption{Complete Certified Robustness Analysis}
\label{alg:robust_complete}
\begin{algorithmic}[1]
\REQUIRE Model $f$, dataset $\mathcal{D}$, perturbation bound $\epsilon$, attack methods
\ENSURE Lipschitz constant $L$, certified bounds, robustness certificates
\STATE // Train robust base model
\STATE $f \leftarrow \text{train\_robust\_model}(\mathcal{D})$
\STATE // Initialize adversarial attack methods
\STATE $\text{attacks} \leftarrow [\text{FGSM}, \text{PGD}, \text{C\&W}]$
\STATE $L\_estimates \leftarrow []$
\STATE $\text{certificates} \leftarrow []$
\FOR{each sample $(x_i, y_i) \in \mathcal{D}$}
    \STATE $\text{local\_L} \leftarrow []$
    \FOR{each attack method $A \in \text{attacks}$}
        \STATE // Generate adversarial example
        \STATE $x_i^{adv} \leftarrow A(f, x_i, \epsilon)$
        \STATE $\delta_i \leftarrow x_i^{adv} - x_i$
        \STATE // Compute prediction change
        \STATE $\Delta f_i \leftarrow |f(x_i^{adv}) - f(x_i)|$
        \STATE // Estimate local Lipschitz constant
        \STATE $L_{i,A} \leftarrow \frac{\Delta f_i}{\|\delta_i\|_2}$
        \STATE $\text{local\_L}.\text{append}(L_{i,A})$
    \ENDFOR
    \STATE $L_i \leftarrow \max(\text{local\_L})$
    \STATE $L\_estimates.\text{append}(L_i)$
    \STATE // Compute certificate for this sample
    \STATE $\text{cert}_i \leftarrow L_i \cdot \epsilon$
    \STATE $\text{certificates}.\text{append}(\text{cert}_i)$
\ENDFOR
\STATE // Global Lipschitz estimate
\STATE $L \leftarrow \text{percentile}(L\_estimates, 95)$ // Conservative estimate
\STATE // Certified bound
\STATE $\text{certified\_bound} \leftarrow L \cdot \epsilon$
\STATE // Robustness statistics
\STATE $\text{robust\_accuracy} \leftarrow \text{compute\_robust\_accuracy}(f, \mathcal{D}, \epsilon)$
\RETURN $L$, certified\_bound, certificates, robust\_accuracy
\end{algorithmic}
\end{algorithm}

\subsubsection{Adversarial Attack Implementations}

\textbf{Fast Gradient Sign Method (FGSM):}
$$x^{adv} = x + \epsilon \cdot \text{sign}(\nabla_x J(f(x), y))$$

\textbf{Projected Gradient Descent (PGD):}
$$x^{adv}_{t+1} = \Pi_{x+S}(x^{adv}_t + \alpha \cdot \text{sign}(\nabla_x J(f(x^{adv}_t), y)))$$

where $\Pi_{x+S}$ projects onto the allowed perturbation set $S$.

\textbf{Carlini \& Wagner (C\&W):}
$$\min_\delta \|\delta\|_2 + c \cdot \max(0, f(x+\delta) - f(x) - \kappa)$$

\section{Complexity Analysis Summary}

\begin{table}[htbp]
\centering
\caption{Algorithm Complexity Summary}
\begin{tabular}{lcc}
\toprule
\textbf{Algorithm} & \textbf{Time Complexity} & \textbf{Space Complexity} \\
\midrule
Nash Equilibrium & $O(n^3 T)$ & $O(n^2)$ \\
Information-Theoretic & $O(k^2 n \log n)$ & $O(kn)$ \\
Quantum Encoding & $O(2^k + d)$ & $O(2^k)$ \\
Adversarial Robustness & $O(n \cdot T_{adv})$ & $O(n)$ \\
\bottomrule
\end{tabular}
\end{table}

where $n$ is dataset size, $k$ is feature count, $d$ is feature dimension, $T$ is convergence iterations, and $T_{adv}$ is adversarial generation time.

\section{Implementation Considerations}

\subsection{Numerical Stability}

\begin{itemize}
\item Use log-space computations for entropy calculations to avoid underflow
\item Implement adaptive step sizes in Nash equilibrium iteration
\item Apply quantum state normalization after each amplitude computation
\item Use robust numerical methods for Lipschitz constant estimation
\end{itemize}

\subsection{Scalability Optimizations}

\begin{itemize}
\item Parallel computation of mutual information across features
\item Batch processing for quantum state encoding
\item GPU acceleration for adversarial example generation
\item Distributed Nash equilibrium computation for large player sets
\end{itemize}

\subsection{Parameter Tuning Guidelines}

\begin{table}[htbp]
\centering
\caption{Recommended Parameter Ranges}
\begin{tabular}{lcc}
\toprule
\textbf{Parameter} & \textbf{Range} & \textbf{Default} \\
\midrule
Nash convergence $\epsilon$ & $[10^{-8}, 10^{-4}]$ & $10^{-6}$ \\
Quantum qubits $k$ & $[3, 8]$ & $3$ \\
Perturbation bound $\epsilon_{adv}$ & $[0.01, 0.3]$ & $0.1$ \\
Discretization bins & $[5, 20]$ & $10$ \\
\bottomrule
\end{tabular}
\end{table}

\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}