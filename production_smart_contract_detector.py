#!/usr/bin/env python3
"""
üîê Production Smart Contract Vulnerability Detector
Advanced ML techniques without external dependencies
"""

import numpy as np
import pandas as pd
import re
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional

# ML imports (using only sklearn)
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support
from sklearn.linear_model import LogisticRegression
from sklearn.utils.class_weight import compute_class_weight
import xgboost as xgb
import joblib

class ProductionSmartContractDetector:
    """Production-ready smart contract vulnerability detector"""

    def __init__(self):
        self.output_dir = Path("production_sc_models")
        self.output_dir.mkdir(exist_ok=True)

        # Setup logging
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
        self.logger = logging.getLogger(__name__)

        # Model storage
        self.models = {}
        self.vectorizers = {}
        self.encoders = {}
        self.scalers = {}
        self.feature_names = []

        # Real-world vulnerability patterns from actual exploits
        self.vulnerability_patterns = {
            'reentrancy': {
                'severity': 'Critical',
                'description': 'External call before state change allows recursive calling',
                'real_examples': [
                    '''
function withdraw(uint256 _amount) public {
    require(balances[msg.sender] >= _amount);

    // REENTRANCY VULNERABILITY: External call before state change
    (bool success, ) = msg.sender.call{value: _amount}("");
    require(success, "Transfer failed");

    // State change after external call - attackers can re-enter here
    balances[msg.sender] -= _amount;
}
                    ''',
                    '''
function emergencyWithdraw() external {
    uint256 balance = userBalances[msg.sender];
    require(balance > 0, "No balance");

    // Vulnerable pattern: external call before state update
    payable(msg.sender).transfer(balance);
    userBalances[msg.sender] = 0;  // Too late!
}
                    '''
                ],
                'bounty_range': (50000, 500000)
            },
            'integer_overflow': {
                'severity': 'High',
                'description': 'Arithmetic operations without overflow protection',
                'real_examples': [
                    '''
function transfer(address to, uint256 value) public returns (bool) {
    // No SafeMath in Solidity < 0.8.0 - overflow/underflow possible
    balances[msg.sender] -= value;  // Underflow attack vector
    balances[to] += value;          // Overflow attack vector

    emit Transfer(msg.sender, to, value);
    return true;
}
                    ''',
                    '''
function batchMint(address[] memory recipients, uint256[] memory amounts) external onlyOwner {
    for (uint i = 0; i < recipients.length; i++) {
        totalSupply += amounts[i];      // Overflow possible
        balances[recipients[i]] += amounts[i];  // Overflow possible
    }
}
                    '''
                ],
                'bounty_range': (25000, 200000)
            },
            'access_control': {
                'severity': 'High',
                'description': 'Missing or insufficient access control mechanisms',
                'real_examples': [
                    '''
function changeOwner(address newOwner) external {
    // CRITICAL: Missing access control modifier!
    owner = newOwner;
    emit OwnerChanged(owner, newOwner);
}

function withdraw() external {
    // Anyone can drain the contract!
    payable(msg.sender).transfer(address(this).balance);
}
                    ''',
                    '''
function emergencyPause() external {
    // Should have onlyOwner modifier
    paused = true;
    emit EmergencyPause(msg.sender);
}

function upgradeContract(address newImplementation) external {
    // Missing authorization check
    implementation = newImplementation;
}
                    '''
                ],
                'bounty_range': (30000, 300000)
            },
            'unchecked_call': {
                'severity': 'Medium',
                'description': 'External calls without checking return values',
                'real_examples': [
                    '''
function executeTransaction(address target, bytes memory data) external onlyOwner {
    // Return value not checked - could silently fail
    target.call(data);
    emit TransactionExecuted(target, data);
}
                    ''',
                    '''
function batchTransfer(address[] memory recipients, uint256[] memory amounts) external {
    for (uint i = 0; i < recipients.length; i++) {
        // Ignoring return value - transfers could fail silently
        token.transfer(recipients[i], amounts[i]);
    }
    emit BatchTransferCompleted(recipients.length);
}
                    '''
                ],
                'bounty_range': (10000, 80000)
            },
            'timestamp_dependence': {
                'severity': 'Medium',
                'description': 'Logic dependent on manipulable block timestamps',
                'real_examples': [
                    '''
function randomLottery() external payable {
    require(msg.value >= 0.1 ether);

    // WEAK RANDOMNESS: Timestamp can be manipulated by miners
    uint256 random = uint256(keccak256(abi.encodePacked(
        block.timestamp,
        block.difficulty,
        msg.sender
    ))) % 100;

    if (random < 50) {
        payable(msg.sender).transfer(msg.value * 2);
    }
}
                    ''',
                    '''
function canWithdraw(address user) public view returns (bool) {
    // Timestamp dependence: miners can manipulate within ~15 seconds
    return block.timestamp > lastWithdrawal[user] + withdrawalDelay;
}
                    '''
                ],
                'bounty_range': (5000, 50000)
            },
            'delegatecall_injection': {
                'severity': 'Critical',
                'description': 'Unsafe delegatecall allowing code injection',
                'real_examples': [
                    '''
contract VulnerableProxy {
    address public implementation;

    function upgrade(address newImplementation) external {
        // CRITICAL: Missing access control for upgrade
        implementation = newImplementation;
    }

    fallback() external payable {
        address impl = implementation;
        assembly {
            calldatacopy(0, 0, calldatasize())
            let result := delegatecall(gas(), impl, 0, calldatasize(), 0, 0)
            returndatacopy(0, 0, returndatasize())

            switch result
            case 0 { revert(0, returndatasize()) }
            default { return(0, returndatasize()) }
        }
    }
}
                    '''
                ],
                'bounty_range': (100000, 1000000)
            }
        }

    def generate_production_dataset(self, n_samples: int = 4000) -> pd.DataFrame:
        """Generate production-quality dataset with realistic patterns"""
        self.logger.info(f"üîê Generating {n_samples:,} production smart contract samples...")

        # Real DeFi protocols with market cap tiers
        protocols = {
            'tier1': {
                'names': ['Uniswap', 'Compound', 'Aave', 'MakerDAO', 'Curve'],
                'bounty_multiplier': 3.0,
                'weight': 0.25
            },
            'tier2': {
                'names': ['SushiSwap', 'Yearn', 'Synthetix', 'Balancer', '1inch'],
                'bounty_multiplier': 2.0,
                'weight': 0.40
            },
            'tier3': {
                'names': ['PancakeSwap', 'dYdX', 'Convex', 'Frax', 'Liquity'],
                'bounty_multiplier': 1.5,
                'weight': 0.35
            }
        }

        contract_types = {
            'token': {'types': ['ERC20', 'ERC721', 'ERC1155'], 'risk_multiplier': 1.2},
            'defi': {'types': ['DEX', 'AMM', 'Vault', 'Pool', 'Strategy'], 'risk_multiplier': 2.0},
            'infrastructure': {'types': ['Proxy', 'Factory', 'Router', 'Oracle'], 'risk_multiplier': 1.8},
            'governance': {'types': ['Governor', 'Timelock', 'Voting'], 'risk_multiplier': 1.5}
        }

        all_data = []

        # Generate balanced samples
        samples_per_vuln = n_samples // len(self.vulnerability_patterns)

        for vuln_type, vuln_info in self.vulnerability_patterns.items():
            for i in range(samples_per_vuln):
                # Select protocol tier
                tier_names = list(protocols.keys())
                tier_weights = [protocols[t]['weight'] for t in tier_names]
                tier = np.random.choice(tier_names, p=tier_weights)

                protocol_data = protocols[tier]
                protocol = np.random.choice(protocol_data['names'])

                # Select contract type
                contract_category = np.random.choice(list(contract_types.keys()))
                contract_data = contract_types[contract_category]
                contract_type = np.random.choice(contract_data['types'])

                # Select realistic code example
                if vuln_info['real_examples']:
                    code_snippet = np.random.choice(vuln_info['real_examples'])
                    # Add realistic variations
                    code_snippet = self._add_realistic_variations(code_snippet, vuln_type)
                else:
                    code_snippet = self._generate_fallback_code(vuln_type)

                # Calculate realistic bounty based on multiple factors
                bounty_min, bounty_max = vuln_info['bounty_range']
                base_bounty = np.random.uniform(bounty_min, bounty_max)

                # Apply multipliers
                final_bounty = (base_bounty *
                              protocol_data['bounty_multiplier'] *
                              contract_data['risk_multiplier'] *
                              np.random.uniform(0.8, 1.4))

                # Extract comprehensive features
                features = self._extract_production_features(code_snippet)

                record = {
                    'id': f"prod_{vuln_type}_{i+1}",
                    'vulnerability_type': vuln_type,
                    'severity_level': vuln_info['severity'],
                    'protocol': protocol,
                    'protocol_tier': tier,
                    'contract_type': contract_type,
                    'contract_category': contract_category,
                    'code_snippet': code_snippet,
                    'bounty_amount': round(final_bounty, 2),
                    'description': f"{vuln_info['severity']} {vuln_type} in {protocol} {contract_type}",
                    'cve_score': self._calculate_realistic_cve_score(vuln_info['severity']),
                    **features
                }

                all_data.append(record)

        df = pd.DataFrame(all_data)

        # Add realistic noise and multi-vulnerability contracts
        df = self._enhance_dataset_realism(df)

        # Save dataset
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        csv_path = self.output_dir / f"production_dataset_{timestamp}.csv"
        df.to_csv(csv_path, index=False)

        self.logger.info(f"‚úÖ Generated {len(df):,} production samples")
        self.logger.info(f"üí∞ Bounty range: ${df['bounty_amount'].min():,.0f} - ${df['bounty_amount'].max():,.0f}")
        self.logger.info(f"üîê Vulnerability distribution:")
        for vuln, count in df['vulnerability_type'].value_counts().items():
            self.logger.info(f"   {vuln}: {count}")

        return df

    def _extract_production_features(self, code: str) -> Dict:
        """Extract production-grade features from smart contract code"""
        features = {}

        # Clean and analyze code
        lines = [line.strip() for line in code.split('\n') if line.strip()]
        code_clean = ' '.join(lines)

        # Basic code metrics
        features['line_count'] = len(lines)
        features['char_count'] = len(code_clean)
        features['word_count'] = len(code_clean.split())

        # Function analysis
        functions = re.findall(r'function\s+(\w+)', code, re.IGNORECASE)
        features['function_count'] = len(functions)
        features['public_functions'] = len(re.findall(r'function\s+\w+.*?public', code, re.IGNORECASE))
        features['external_functions'] = len(re.findall(r'function\s+\w+.*?external', code, re.IGNORECASE))
        features['payable_functions'] = len(re.findall(r'function\s+\w+.*?payable', code, re.IGNORECASE))
        features['view_functions'] = len(re.findall(r'function\s+\w+.*?view', code, re.IGNORECASE))

        # Security mechanisms
        features['require_count'] = len(re.findall(r'require\s*\(', code))
        features['assert_count'] = len(re.findall(r'assert\s*\(', code))
        features['revert_count'] = len(re.findall(r'revert\s*\(', code))
        features['modifier_count'] = len(re.findall(r'modifier\s+\w+', code))

        # External interactions (CRITICAL for security)
        features['external_calls'] = len(re.findall(r'\.call\s*\(|\.delegatecall\s*\(|\.staticcall\s*\(', code))
        features['transfer_calls'] = len(re.findall(r'\.transfer\s*\(|\.send\s*\(', code))
        features['low_level_calls'] = len(re.findall(r'\.call\s*\{|\.delegatecall\s*\{', code))

        # State and storage
        features['state_variables'] = len(re.findall(r'(mapping|uint\d*|int\d*|address|bool|string)\s+(public|private|internal)', code))
        features['mapping_count'] = len(re.findall(r'mapping\s*\(', code))
        features['array_usage'] = len(re.findall(r'\[\]|\[.*?\]', code))

        # Access control patterns
        features['onlyowner_usage'] = len(re.findall(r'onlyOwner', code, re.IGNORECASE))
        features['msg_sender_checks'] = len(re.findall(r'msg\.sender', code))
        features['tx_origin_usage'] = len(re.findall(r'tx\.origin', code))

        # Arithmetic and overflow risks
        features['arithmetic_ops'] = len(re.findall(r'[+\-*/]', code))
        features['safemath_usage'] = len(re.findall(r'SafeMath', code, re.IGNORECASE))
        features['unchecked_blocks'] = len(re.findall(r'unchecked\s*\{', code))

        # Time and randomness
        features['timestamp_usage'] = len(re.findall(r'block\.timestamp|now', code))
        features['block_vars_usage'] = len(re.findall(r'block\.(number|difficulty|coinbase)', code))
        features['randomness_patterns'] = len(re.findall(r'keccak256|sha256|random', code, re.IGNORECASE))

        # Low-level and assembly
        features['assembly_blocks'] = len(re.findall(r'assembly\s*\{', code))
        features['inline_assembly'] = 1 if 'assembly' in code else 0

        # Events and logging
        features['event_declarations'] = len(re.findall(r'event\s+\w+', code))
        features['emit_statements'] = len(re.findall(r'emit\s+\w+', code))

        # Special functions
        features['fallback_function'] = 1 if 'fallback' in code else 0
        features['receive_function'] = 1 if 'receive' in code else 0
        features['constructor_present'] = 1 if 'constructor' in code else 0

        # Complexity and quality indicators
        features['cyclomatic_complexity'] = self._calculate_cyclomatic_complexity(code)
        features['nesting_depth'] = self._calculate_nesting_depth(code)
        features['comment_ratio'] = len(re.findall(r'//.*', code)) / max(len(lines), 1)

        # Security anti-patterns
        features['reentrancy_risk'] = self._detect_reentrancy_patterns(code)
        features['overflow_risk'] = self._detect_overflow_patterns(code)
        features['access_risk'] = self._detect_access_control_issues(code)

        return features

    def _calculate_cyclomatic_complexity(self, code: str) -> int:
        """Calculate cyclomatic complexity"""
        complexity = 1
        decision_points = ['if', 'else if', 'for', 'while', 'case', '&&', '||', '?', 'catch']

        for pattern in decision_points:
            complexity += len(re.findall(pattern, code, re.IGNORECASE))

        return complexity

    def _calculate_nesting_depth(self, code: str) -> int:
        """Calculate maximum nesting depth"""
        depth = 0
        max_depth = 0

        for char in code:
            if char == '{':
                depth += 1
                max_depth = max(max_depth, depth)
            elif char == '}':
                depth = max(0, depth - 1)

        return max_depth

    def _detect_reentrancy_patterns(self, code: str) -> float:
        """Detect reentrancy vulnerability patterns"""
        risk_score = 0.0

        # External calls before state changes
        lines = code.split('\n')
        external_call_found = False
        state_change_after = False

        for line in lines:
            line = line.strip()
            if '.call(' in line or '.transfer(' in line or '.send(' in line:
                external_call_found = True
            elif external_call_found and ('-=' in line or '+=' in line or '=' in line):
                state_change_after = True
                risk_score += 0.8
                break

        # Missing reentrancy guards
        if external_call_found and 'nonReentrant' not in code:
            risk_score += 0.5

        return min(risk_score, 1.0)

    def _detect_overflow_patterns(self, code: str) -> float:
        """Detect integer overflow vulnerability patterns"""
        risk_score = 0.0

        # Arithmetic without SafeMath (for older Solidity)
        if ('+=' in code or '-=' in code or '*=' in code) and 'SafeMath' not in code:
            risk_score += 0.6

        # No unchecked blocks in newer Solidity
        if ('pragma solidity ^0.8' in code or 'pragma solidity >=0.8' in code) and 'unchecked' not in code:
            risk_score += 0.3

        return min(risk_score, 1.0)

    def _detect_access_control_issues(self, code: str) -> float:
        """Detect access control vulnerability patterns"""
        risk_score = 0.0

        # Critical functions without access control
        critical_functions = ['changeOwner', 'withdraw', 'transfer', 'mint', 'burn']

        for func in critical_functions:
            if func in code and 'onlyOwner' not in code and 'require(' not in code:
                risk_score += 0.4

        return min(risk_score, 1.0)

    def _add_realistic_variations(self, base_code: str, vuln_type: str) -> str:
        """Add realistic variations to make training data more diverse"""
        variations = [
            "// Security audit: Review required",
            "uint256 constant MAX_SUPPLY = 1000000 * 10**18;",
            "event SecurityEvent(address indexed user, uint256 indexed amount);",
            "modifier whenNotPaused() { require(!paused, \"Contract paused\"); _; }",
            "using SafeMath for uint256;",
        ]

        # Add contextual variations based on vulnerability type
        if vuln_type == 'reentrancy':
            variations.append("// TODO: Add reentrancy guard")
        elif vuln_type == 'access_control':
            variations.append("// FIXME: Add proper access control")

        variation = np.random.choice(variations)
        return f"{variation}\n{base_code}"

    def _enhance_dataset_realism(self, df: pd.DataFrame) -> pd.DataFrame:
        """Add realistic complexity to dataset"""
        enhanced_data = []

        # Add contracts with multiple vulnerabilities (realistic scenario)
        for _ in range(int(len(df) * 0.1)):  # 10% multi-vuln contracts
            vuln_types = np.random.choice(list(self.vulnerability_patterns.keys()), size=2, replace=False)
            combined_vuln = f"{vuln_types[0]}+{vuln_types[1]}"

            base_row = df.sample(1).iloc[0].copy()
            base_row['vulnerability_type'] = combined_vuln
            base_row['severity_level'] = 'Critical'  # Multi-vuln is always critical
            base_row['bounty_amount'] *= 1.8  # Higher bounty for multiple vulnerabilities

            enhanced_data.append(base_row)

        # Add edge cases
        for _ in range(int(len(df) * 0.05)):  # 5% edge cases
            edge_row = df.sample(1).iloc[0].copy()
            edge_row['vulnerability_type'] = 'edge_case'
            edge_row['severity_level'] = np.random.choice(['Low', 'Medium'])
            edge_row['bounty_amount'] *= 0.5

            enhanced_data.append(edge_row)

        if enhanced_data:
            enhanced_df = pd.DataFrame(enhanced_data)
            df = pd.concat([df, enhanced_df], ignore_index=True)

        return df

    def _calculate_realistic_cve_score(self, severity: str) -> float:
        """Calculate realistic CVE scores with proper distribution"""
        base_scores = {
            'Critical': (9.0, 10.0),
            'High': (7.0, 8.9),
            'Medium': (4.0, 6.9),
            'Low': (0.1, 3.9)
        }
        min_score, max_score = base_scores[severity]
        return round(np.random.uniform(min_score, max_score), 1)

    def prepare_production_features(self, df: pd.DataFrame) -> Tuple[np.ndarray, List[str]]:
        """Prepare production-grade feature matrix"""
        self.logger.info("üîß Preparing production features...")

        # Define comprehensive feature names
        feature_names = [
            # Basic code metrics
            'line_count', 'char_count', 'word_count',
            # Function analysis
            'function_count', 'public_functions', 'external_functions',
            'payable_functions', 'view_functions',
            # Security mechanisms
            'require_count', 'assert_count', 'revert_count', 'modifier_count',
            # External interactions
            'external_calls', 'transfer_calls', 'low_level_calls',
            # State and storage
            'state_variables', 'mapping_count', 'array_usage',
            # Access control
            'onlyowner_usage', 'msg_sender_checks', 'tx_origin_usage',
            # Arithmetic
            'arithmetic_ops', 'safemath_usage', 'unchecked_blocks',
            # Time and randomness
            'timestamp_usage', 'block_vars_usage', 'randomness_patterns',
            # Low-level
            'assembly_blocks', 'inline_assembly',
            # Events
            'event_declarations', 'emit_statements',
            # Special functions
            'fallback_function', 'receive_function', 'constructor_present',
            # Complexity
            'cyclomatic_complexity', 'nesting_depth', 'comment_ratio',
            # Risk patterns
            'reentrancy_risk', 'overflow_risk', 'access_risk',
            # Context features
            'cve_score', 'protocol_tier_score', 'contract_risk_score', 'severity_score'
        ]

        features = []

        for _, row in df.iterrows():
            # Calculate contextual scores
            tier_scores = {'tier1': 1.0, 'tier2': 0.8, 'tier3': 0.6}
            protocol_tier_score = tier_scores.get(row['protocol_tier'], 0.5)

            contract_risk_scores = {'defi': 1.0, 'infrastructure': 0.9, 'governance': 0.8, 'token': 0.7}
            contract_risk_score = contract_risk_scores.get(row['contract_category'], 0.5)

            severity_scores = {'Critical': 1.0, 'High': 0.8, 'Medium': 0.6, 'Low': 0.4}
            severity_score = severity_scores[row['severity_level']]

            # Build feature vector
            feature_vector = [
                # Extract all features from the row
                row.get('line_count', 0), row.get('char_count', 0), row.get('word_count', 0),
                row.get('function_count', 0), row.get('public_functions', 0), row.get('external_functions', 0),
                row.get('payable_functions', 0), row.get('view_functions', 0),
                row.get('require_count', 0), row.get('assert_count', 0), row.get('revert_count', 0),
                row.get('modifier_count', 0), row.get('external_calls', 0), row.get('transfer_calls', 0),
                row.get('low_level_calls', 0), row.get('state_variables', 0), row.get('mapping_count', 0),
                row.get('array_usage', 0), row.get('onlyowner_usage', 0), row.get('msg_sender_checks', 0),
                row.get('tx_origin_usage', 0), row.get('arithmetic_ops', 0), row.get('safemath_usage', 0),
                row.get('unchecked_blocks', 0), row.get('timestamp_usage', 0), row.get('block_vars_usage', 0),
                row.get('randomness_patterns', 0), row.get('assembly_blocks', 0), row.get('inline_assembly', 0),
                row.get('event_declarations', 0), row.get('emit_statements', 0), row.get('fallback_function', 0),
                row.get('receive_function', 0), row.get('constructor_present', 0),
                row.get('cyclomatic_complexity', 1), row.get('nesting_depth', 0), row.get('comment_ratio', 0),
                row.get('reentrancy_risk', 0), row.get('overflow_risk', 0), row.get('access_risk', 0),
                row['cve_score'], protocol_tier_score, contract_risk_score, severity_score
            ]

            features.append(feature_vector)

        self.feature_names = feature_names
        return np.array(features), feature_names

    def train_production_ensemble(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """Train production ensemble with advanced techniques"""
        self.logger.info("ü§ñ Training production ensemble...")

        # Handle class imbalance with class weights (instead of SMOTE)
        classes = np.unique(y)
        class_weights = compute_class_weight('balanced', classes=classes, y=y)
        class_weight_dict = dict(zip(classes, class_weights))

        self.logger.info(f"Applied class weights for imbalance: {class_weight_dict}")

        # Label encoding
        label_encoder = LabelEncoder()
        y_encoded = label_encoder.fit_transform(y)
        self.encoders['vulnerability'] = label_encoder

        # Feature scaling
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        self.scalers['vulnerability'] = scaler

        # Train/test split
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
        )

        # Advanced ensemble models with hyperparameter tuning
        models = {
            'random_forest': RandomForestClassifier(
                random_state=42,
                class_weight='balanced',
                n_jobs=-1
            ),
            'xgboost': xgb.XGBClassifier(
                random_state=42,
                eval_metric='mlogloss'
            ),
            'gradient_boosting': GradientBoostingClassifier(
                random_state=42
            )
        }

        # Hyperparameter grids (simplified for speed)
        param_grids = {
            'random_forest': {
                'n_estimators': [100, 200],
                'max_depth': [10, 15],
                'min_samples_split': [5, 10]
            },
            'xgboost': {
                'n_estimators': [100, 200],
                'max_depth': [6, 8],
                'learning_rate': [0.1, 0.15]
            }
        }

        # Train and tune models
        best_models = []
        model_results = {}

        for name, model in models.items():
            self.logger.info(f"  Training and tuning {name}...")

            if name in param_grids:
                # Hyperparameter tuning
                grid_search = GridSearchCV(
                    model, param_grids[name],
                    cv=3, scoring='accuracy', n_jobs=-1
                )
                grid_search.fit(X_train, y_train)
                best_model = grid_search.best_estimator_
                self.logger.info(f"    Best params: {grid_search.best_params_}")
            else:
                best_model = model
                best_model.fit(X_train, y_train)

            # Evaluate model
            cv_scores = cross_val_score(best_model, X_train, y_train, cv=3, scoring='accuracy')
            y_pred_test = best_model.predict(X_test)
            test_accuracy = accuracy_score(y_test, y_pred_test)

            model_results[name] = {
                'cv_accuracy_mean': cv_scores.mean(),
                'cv_accuracy_std': cv_scores.std(),
                'test_accuracy': test_accuracy
            }

            best_models.append((name, best_model))
            self.logger.info(f"    CV: {cv_scores.mean():.3f}¬±{cv_scores.std():.3f}, Test: {test_accuracy:.3f}")

        # Create voting ensemble
        voting_classifier = VotingClassifier(
            estimators=best_models,
            voting='soft'  # Use probabilities for better performance
        )

        # Train ensemble
        self.logger.info("  Training voting ensemble...")
        cv_scores = cross_val_score(voting_classifier, X_train, y_train, cv=5, scoring='accuracy')
        voting_classifier.fit(X_train, y_train)

        self.models['vulnerability_classifier'] = voting_classifier

        # Final evaluation
        y_pred_final = voting_classifier.predict(X_test)
        test_accuracy = accuracy_score(y_test, y_pred_final)
        precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_final, average='weighted')

        # Classification report
        class_report = classification_report(
            y_test, y_pred_final,
            target_names=label_encoder.classes_,
            output_dict=True
        )

        results = {
            'model_type': 'VotingClassifier',
            'cv_accuracy_mean': cv_scores.mean(),
            'cv_accuracy_std': cv_scores.std(),
            'test_accuracy': test_accuracy,
            'test_precision': precision,
            'test_recall': recall,
            'test_f1': f1,
            'classification_report': class_report,
            'class_names': label_encoder.classes_.tolist(),
            'model_comparison': model_results,
            'features_count': X.shape[1]
        }

        self.logger.info(f"‚úÖ Production ensemble: CV={cv_scores.mean():.3f}¬±{cv_scores.std():.3f}, Test={test_accuracy:.3f}")
        return results

    def analyze_smart_contract(self, code: str, description: str = "") -> Dict:
        """Analyze smart contract for vulnerabilities"""

        if 'vulnerability_classifier' not in self.models:
            return {'error': 'Model not trained yet'}

        try:
            # Extract features
            features = self._extract_production_features(code)

            # Create feature vector with default values for missing features
            feature_vector = []
            for feature_name in self.feature_names[:-4]:  # Exclude context features
                feature_vector.append(features.get(feature_name, 0))

            # Add context features (default values)
            feature_vector.extend([7.0, 0.8, 0.8, 0.8])  # cve_score, protocol_tier, contract_risk, severity

            # Scale features
            features_scaled = self.scalers['vulnerability'].transform([feature_vector])

            # Predict vulnerability
            prediction = self.models['vulnerability_classifier'].predict(features_scaled)[0]
            vulnerability = self.encoders['vulnerability'].inverse_transform([prediction])[0]

            # Get prediction probabilities
            probabilities = self.models['vulnerability_classifier'].predict_proba(features_scaled)[0]
            confidence = float(np.max(probabilities))

            # Get top 3 predictions
            class_names = self.encoders['vulnerability'].classes_
            top_indices = np.argsort(probabilities)[-3:][::-1]
            top_predictions = [
                {'vulnerability': class_names[i], 'confidence': float(probabilities[i])}
                for i in top_indices
            ]

            # Calculate comprehensive risk assessment
            risk_assessment = self._calculate_risk_assessment(features, vulnerability, confidence)

            # Generate security recommendations
            recommendations = self._generate_security_recommendations(vulnerability, features)

            return {
                'primary_vulnerability': vulnerability,
                'confidence': confidence,
                'top_predictions': top_predictions,
                'risk_assessment': risk_assessment,
                'features_analyzed': features,
                'security_recommendations': recommendations,
                'analysis_metadata': {
                    'model_type': 'Production Ensemble',
                    'features_used': len(feature_vector),
                    'analysis_timestamp': datetime.now().isoformat()
                }
            }

        except Exception as e:
            return {'error': f'Analysis failed: {str(e)}'}

    def _calculate_risk_assessment(self, features: Dict, vulnerability: str, confidence: float) -> Dict:
        """Calculate comprehensive risk assessment"""

        # Base risk scores by vulnerability type
        base_risks = {
            'reentrancy': 0.9,
            'delegatecall_injection': 0.95,
            'access_control': 0.8,
            'integer_overflow': 0.7,
            'unchecked_call': 0.6,
            'timestamp_dependence': 0.5
        }

        base_risk = base_risks.get(vulnerability.split('+')[0], 0.5)  # Handle multi-vulnerability

        # Risk factors
        risk_factors = {
            'external_calls': features.get('external_calls', 0) > 0,
            'low_level_calls': features.get('low_level_calls', 0) > 0,
            'missing_access_control': features.get('onlyowner_usage', 0) == 0 and features.get('require_count', 0) < 2,
            'complex_logic': features.get('cyclomatic_complexity', 1) > 10,
            'assembly_usage': features.get('assembly_blocks', 0) > 0,
            'timestamp_dependency': features.get('timestamp_usage', 0) > 0,
            'unchecked_arithmetic': features.get('safemath_usage', 0) == 0 and features.get('arithmetic_ops', 0) > 5
        }

        # Calculate weighted risk score
        risk_weights = {
            'external_calls': 0.2,
            'low_level_calls': 0.25,
            'missing_access_control': 0.15,
            'complex_logic': 0.1,
            'assembly_usage': 0.15,
            'timestamp_dependency': 0.05,
            'unchecked_arithmetic': 0.1
        }

        weighted_risk = sum(risk_weights[factor] for factor, present in risk_factors.items() if present)
        final_risk_score = min((base_risk + weighted_risk) * confidence, 1.0)

        # Risk level
        if final_risk_score >= 0.8:
            risk_level = 'CRITICAL'
        elif final_risk_score >= 0.6:
            risk_level = 'HIGH'
        elif final_risk_score >= 0.4:
            risk_level = 'MEDIUM'
        else:
            risk_level = 'LOW'

        return {
            'risk_score': final_risk_score,
            'risk_level': risk_level,
            'risk_factors': risk_factors,
            'base_vulnerability_risk': base_risk,
            'confidence_adjusted_risk': final_risk_score
        }

    def _generate_security_recommendations(self, vulnerability: str, features: Dict) -> List[str]:
        """Generate specific security recommendations"""
        recommendations = []

        # Vulnerability-specific recommendations
        vuln_recommendations = {
            'reentrancy': [
                "Implement checks-effects-interactions pattern",
                "Use reentrancy guard (nonReentrant modifier)",
                "Update state variables before external calls",
                "Consider using pull over push payment pattern"
            ],
            'integer_overflow': [
                "Use SafeMath library for arithmetic operations",
                "Upgrade to Solidity 0.8+ with built-in overflow protection",
                "Add explicit bounds checking for critical calculations",
                "Use unchecked blocks only when overflow is intended"
            ],
            'access_control': [
                "Implement proper access control modifiers (onlyOwner)",
                "Use OpenZeppelin's AccessControl for role-based permissions",
                "Add require statements for function authorization",
                "Consider multi-signature for critical operations"
            ],
            'unchecked_call': [
                "Always check return values of external calls",
                "Use require() to handle call failures",
                "Consider using transfer() instead of call() for ETH transfers",
                "Implement proper error handling for failed calls"
            ],
            'timestamp_dependence': [
                "Avoid using block.timestamp for critical logic",
                "Use block numbers instead of timestamps when possible",
                "Implement tolerance ranges for time-based conditions",
                "Consider using external oracles for time-sensitive operations"
            ],
            'delegatecall_injection': [
                "Validate implementation addresses before delegatecall",
                "Use proxy patterns with proper access controls",
                "Implement upgradeable contracts carefully",
                "Consider using CREATE2 for deterministic addresses"
            ]
        }

        # Add vulnerability-specific recommendations
        vuln_key = vulnerability.split('+')[0]  # Handle multi-vulnerability
        if vuln_key in vuln_recommendations:
            recommendations.extend(vuln_recommendations[vuln_key])

        # Feature-based recommendations
        if features.get('require_count', 0) < 2:
            recommendations.append("Add more input validation with require statements")

        if features.get('external_calls', 0) > 0 and features.get('require_count', 0) == 0:
            recommendations.append("Add proper error handling for external calls")

        if features.get('assembly_blocks', 0) > 0:
            recommendations.append("Review assembly code for potential vulnerabilities")

        if features.get('cyclomatic_complexity', 1) > 15:
            recommendations.append("Consider refactoring complex functions to reduce complexity")

        # General security recommendations
        recommendations.extend([
            "Conduct thorough security audit before deployment",
            "Implement comprehensive unit and integration tests",
            "Use static analysis tools for vulnerability detection",
            "Consider bug bounty programs for additional security review"
        ])

        return list(set(recommendations))  # Remove duplicates

    def save_production_models(self):
        """Save production models with metadata"""
        self.logger.info("üíæ Saving production models...")

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        # Save models
        for model_name, model in self.models.items():
            model_path = self.output_dir / f"{model_name}_{timestamp}.pkl"
            joblib.dump(model, model_path)

        # Save preprocessors
        for name, obj in {**self.scalers, **self.vectorizers, **self.encoders}.items():
            obj_path = self.output_dir / f"{name}_{timestamp}.pkl"
            joblib.dump(obj, obj_path)

        # Save feature names and metadata
        metadata = {
            'feature_names': self.feature_names,
            'model_type': 'ProductionVotingEnsemble',
            'training_timestamp': timestamp,
            'vulnerability_types': list(self.vulnerability_patterns.keys())
        }

        metadata_path = self.output_dir / f"model_metadata_{timestamp}.json"
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)

        self.logger.info(f"‚úÖ Production models saved with timestamp: {timestamp}")
        return timestamp

    def run_production_training(self):
        """Run complete production training pipeline"""
        self.logger.info("üöÄ Starting production smart contract training...")

        try:
            # Generate production dataset
            df = self.generate_production_dataset(n_samples=4000)

            # Prepare production features
            X, feature_names = self.prepare_production_features(df)
            y = df['vulnerability_type'].values

            # Train production ensemble
            results = self.train_production_ensemble(X, y)

            # Save models
            timestamp = self.save_production_models()

            self.logger.info("‚úÖ Production training completed successfully!")

            return {
                'status': 'success',
                'results': results,
                'timestamp': timestamp,
                'dataset_size': len(df),
                'feature_count': len(feature_names)
            }

        except Exception as e:
            self.logger.error(f"‚ùå Production training failed: {e}")
            import traceback
            self.logger.error(f"Traceback: {traceback.format_exc()}")
            return {'status': 'error', 'error': str(e)}

def main():
    """Main execution with comprehensive testing"""
    print("üîê PRODUCTION SMART CONTRACT VULNERABILITY DETECTOR")
    print("=" * 80)

    detector = ProductionSmartContractDetector()

    # Run production training
    results = detector.run_production_training()

    if results['status'] == 'success':
        print(f"\n‚úÖ PRODUCTION TRAINING COMPLETE!")
        print(f"üìä Dataset: {results['dataset_size']:,} samples")
        print(f"üîß Features: {results['feature_count']} production features")
        print(f"ü§ñ Model: {results['results']['model_type']}")
        print(f"üéØ Test Accuracy: {results['results']['test_accuracy']:.3f}")
        print(f"üìà Test F1-Score: {results['results']['test_f1']:.3f}")
        print(f"üíæ Models saved: {results['timestamp']}")

        # Test with multiple real vulnerable contracts
        print(f"\nüß™ TESTING WITH REAL VULNERABLE CONTRACTS:")
        print("=" * 60)

        test_contracts = [
            {
                'name': 'Classic Reentrancy Vulnerability',
                'code': '''
pragma solidity ^0.8.0;

contract VulnerableBank {
    mapping(address => uint256) public balances;

    function deposit() external payable {
        balances[msg.sender] += msg.value;
    }

    function withdraw(uint256 amount) external {
        require(balances[msg.sender] >= amount, "Insufficient balance");

        // CRITICAL VULNERABILITY: External call before state change
        (bool success, ) = msg.sender.call{value: amount}("");
        require(success, "Transfer failed");

        // Attacker can re-enter here before this line executes
        balances[msg.sender] -= amount;
    }
}
                ''',
                'expected': 'reentrancy'
            },
            {
                'name': 'Access Control Bypass',
                'code': '''
pragma solidity ^0.8.0;

contract VulnerableVault {
    address public owner;
    uint256 public totalFunds;

    constructor() {
        owner = msg.sender;
    }

    // CRITICAL: Missing access control!
    function changeOwner(address newOwner) external {
        owner = newOwner;
    }

    // CRITICAL: Anyone can drain funds!
    function emergencyWithdraw() external {
        payable(msg.sender).transfer(address(this).balance);
    }

    function deposit() external payable {
        totalFunds += msg.value;
    }
}
                ''',
                'expected': 'access_control'
            },
            {
                'name': 'Integer Overflow Vulnerability',
                'code': '''
pragma solidity ^0.7.6;  // Older version without overflow protection

contract VulnerableToken {
    mapping(address => uint256) public balances;
    uint256 public totalSupply;

    function transfer(address to, uint256 value) external returns (bool) {
        // VULNERABILITY: No overflow/underflow protection
        balances[msg.sender] -= value;  // Underflow possible
        balances[to] += value;          // Overflow possible

        emit Transfer(msg.sender, to, value);
        return true;
    }

    function mint(address to, uint256 amount) external {
        totalSupply += amount;     // Overflow possible
        balances[to] += amount;    // Overflow possible
    }

    event Transfer(address indexed from, address indexed to, uint256 value);
}
                ''',
                'expected': 'integer_overflow'
            }
        ]

        for i, test_case in enumerate(test_contracts, 1):
            print(f"\nüîç Test {i}: {test_case['name']}")
            print(f"Expected: {test_case['expected']}")

            analysis = detector.analyze_smart_contract(
                test_case['code'],
                f"Test case: {test_case['name']}"
            )

            if 'error' not in analysis:
                print(f"üéØ Detected: {analysis['primary_vulnerability']}")
                print(f"üìä Confidence: {analysis['confidence']:.2%}")
                print(f"‚ö†Ô∏è  Risk Level: {analysis['risk_assessment']['risk_level']}")
                print(f"üìà Risk Score: {analysis['risk_assessment']['risk_score']:.2f}")

                # Check if detection is correct
                predicted = analysis['primary_vulnerability'].split('+')[0]  # Handle multi-vuln
                if predicted == test_case['expected']:
                    print("‚úÖ CORRECT DETECTION!")
                else:
                    print(f"‚ùå Incorrect - Expected: {test_case['expected']}, Got: {predicted}")

                print(f"üîß Top Recommendations:")
                for rec in analysis['security_recommendations'][:3]:
                    print(f"   ‚Ä¢ {rec}")
            else:
                print(f"‚ùå Analysis Error: {analysis['error']}")

    else:
        print(f"\n‚ùå PRODUCTION TRAINING FAILED: {results['error']}")

if __name__ == "__main__":
    main()