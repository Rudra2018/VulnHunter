#!/usr/bin/env python3
"""
Quick Vulnerability Analysis Validator

A production-ready script to quickly validate vulnerability analysis reports
and detect potential false positives based on the trained VulnHunter model.

Usage:
    python3 quick_vulnerability_validator.py <path_to_vulnerability_report.json>
"""

import json
import sys
import os
import re
from typing import Dict, List, Tuple, Any

class QuickVulnerabilityValidator:
    """Quick validation of vulnerability analysis reports."""

    def __init__(self):
        self.validation_rules = self._load_validation_rules()

    def _load_validation_rules(self) -> Dict[str, Any]:
        """Load validation rules for quick checks."""
        return {
            "critical_thresholds": {
                "max_reasonable_vulnerabilities": 500,
                "max_vulnerabilities_per_file": 10,
                "max_critical_count": 20,
                "max_high_count": 100
            },
            "suspicious_patterns": [
                r"unsafe\s*\{\s*transmute",
                r"std::ptr::write",
                r"slice::from_raw_parts",
                r'API_KEY.*=.*"sk-[a-zA-Z0-9]+'
            ],
            "dangerous_claims": [
                "transmute(raw_ptr)",
                "std::ptr::write(ptr, value)",
                "slice::from_raw_parts(ptr, len)",
                'const API_KEY: &str = "sk-'
            ]
        }

    def validate_report(self, report_path: str) -> Dict[str, Any]:
        """Perform quick validation of a vulnerability report."""

        try:
            with open(report_path, 'r') as f:
                report = json.load(f)
        except Exception as e:
            return {
                "status": "ERROR",
                "message": f"Could not load report: {str(e)}",
                "validation_score": 0.0
            }

        # Perform validation checks
        results = {
            "status": "ANALYZED",
            "report_path": report_path,
            "validation_checks": {},
            "red_flags": [],
            "warnings": [],
            "validation_score": 0.0,
            "recommendation": "UNKNOWN"
        }

        # Check 1: Basic structure validation
        results["validation_checks"]["structure"] = self._validate_structure(report, results)

        # Check 2: Vulnerability count validation
        results["validation_checks"]["counts"] = self._validate_counts(report, results)

        # Check 3: Pattern existence validation
        results["validation_checks"]["patterns"] = self._validate_patterns(report, results)

        # Check 4: File reference validation
        results["validation_checks"]["references"] = self._validate_references(report, results)

        # Check 5: Repository path validation
        results["validation_checks"]["repository"] = self._validate_repository(report, results)

        # Calculate overall validation score
        results["validation_score"] = self._calculate_validation_score(results)

        # Make recommendation
        results["recommendation"] = self._make_recommendation(results)

        return results

    def _validate_structure(self, report: Dict[str, Any], results: Dict[str, Any]) -> bool:
        """Validate basic report structure."""

        required_fields = ["total_vulnerabilities", "severity_distribution"]
        missing_fields = [field for field in required_fields if field not in report]

        if missing_fields:
            results["warnings"].append(f"Missing required fields: {missing_fields}")
            return False

        return True

    def _validate_counts(self, report: Dict[str, Any], results: Dict[str, Any]) -> bool:
        """Validate vulnerability counts for reasonableness."""

        total_vulns = report.get("total_vulnerabilities", 0)
        severity_dist = report.get("severity_distribution", {})

        critical_count = severity_dist.get("CRITICAL", 0)
        high_count = severity_dist.get("HIGH", 0)

        thresholds = self.validation_rules["critical_thresholds"]
        issues_found = False

        # Check total vulnerabilities
        if total_vulns > thresholds["max_reasonable_vulnerabilities"]:
            results["red_flags"].append(
                f"Extremely high vulnerability count: {total_vulns} "
                f"(threshold: {thresholds['max_reasonable_vulnerabilities']})"
            )
            issues_found = True

        # Check critical count
        if critical_count > thresholds["max_critical_count"]:
            results["red_flags"].append(
                f"Unrealistic critical vulnerability count: {critical_count} "
                f"(threshold: {thresholds['max_critical_count']})"
            )
            issues_found = True

        # Check high count
        if high_count > thresholds["max_high_count"]:
            results["red_flags"].append(
                f"Unrealistic high vulnerability count: {high_count} "
                f"(threshold: {thresholds['max_high_count']})"
            )
            issues_found = True

        # Calculate vulnerability density
        if "vulnerability_types" in report:
            files_referenced = set()
            for vuln_type, vulnerabilities in report["vulnerability_types"].items():
                if isinstance(vulnerabilities, list):
                    for vuln in vulnerabilities:
                        if "file" in vuln:
                            files_referenced.add(vuln["file"])

            if files_referenced:
                density = total_vulns / len(files_referenced)
                if density > thresholds["max_vulnerabilities_per_file"]:
                    results["red_flags"].append(
                        f"Unrealistic vulnerability density: {density:.1f} per file "
                        f"(threshold: {thresholds['max_vulnerabilities_per_file']})"
                    )
                    issues_found = True

        return not issues_found

    def _validate_patterns(self, report: Dict[str, Any], results: Dict[str, Any]) -> bool:
        """Validate that claimed vulnerable patterns make sense."""

        report_str = json.dumps(report)
        issues_found = False

        # Check for dangerous claims that are likely fabricated
        for claim in self.validation_rules["dangerous_claims"]:
            if claim in report_str:
                results["red_flags"].append(
                    f"Claims dangerous pattern that's rarely found in real code: {claim}"
                )
                issues_found = True

        # Check for excessive .unwrap() claims
        if ".unwrap()" in report_str:
            medium_count = report.get("severity_distribution", {}).get("MEDIUM", 0)
            if medium_count > 2000:
                results["red_flags"].append(
                    f"Claims excessive .unwrap() usage: {medium_count} medium severity issues"
                )
                issues_found = True

        return not issues_found

    def _validate_references(self, report: Dict[str, Any], results: Dict[str, Any]) -> bool:
        """Validate file and line references."""

        issues_found = False

        if "vulnerability_types" in report:
            for vuln_type, vulnerabilities in report["vulnerability_types"].items():
                if isinstance(vulnerabilities, list):
                    for vuln in vulnerabilities:
                        # Check for suspicious line numbers
                        if "line" in vuln:
                            line_num = vuln["line"]
                            if line_num > 10000:
                                results["red_flags"].append(
                                    f"Suspicious line number: {line_num} in {vuln.get('file', 'unknown')}"
                                )
                                issues_found = True
                            elif line_num > 2000:
                                results["warnings"].append(
                                    f"High line number may need verification: {line_num} in {vuln.get('file', 'unknown')}"
                                )

                        # Check for non-existent file patterns
                        if "file" in vuln:
                            file_path = vuln["file"]
                            if "/tmp/" in file_path and "analysis" in file_path:
                                results["red_flags"].append(
                                    f"Suspicious temporary analysis path: {file_path}"
                                )
                                issues_found = True

        return not issues_found

    def _validate_repository(self, report: Dict[str, Any], results: Dict[str, Any]) -> bool:
        """Validate repository path and consistency."""

        repo_path = report.get("repository_analyzed", "")
        issues_found = False

        if repo_path:
            # Check for suspicious paths
            if "/tmp/" in repo_path and "analysis" in repo_path:
                results["red_flags"].append(
                    f"Analysis appears to be on temporary/analysis directory: {repo_path}"
                )
                issues_found = True

            # Check for repository identity confusion
            if "openai" in repo_path.lower() and "codex" in repo_path.lower():
                results["warnings"].append(
                    "Repository path suggests OpenAI Codex - verify this is correct repository"
                )

        return not issues_found

    def _calculate_validation_score(self, results: Dict[str, Any]) -> float:
        """Calculate overall validation score (0.0 = highly suspicious, 1.0 = looks legitimate)."""

        score = 1.0

        # Deduct for red flags (major issues)
        red_flag_count = len(results["red_flags"])
        score -= red_flag_count * 0.2

        # Deduct for warnings (minor issues)
        warning_count = len(results["warnings"])
        score -= warning_count * 0.05

        # Bonus for passing all validation checks
        passed_checks = sum(1 for check in results["validation_checks"].values() if check)
        total_checks = len(results["validation_checks"])
        if passed_checks == total_checks:
            score += 0.1

        return max(0.0, min(1.0, score))

    def _make_recommendation(self, results: Dict[str, Any]) -> str:
        """Make a recommendation based on validation results."""

        score = results["validation_score"]
        red_flag_count = len(results["red_flags"])

        if score < 0.3 or red_flag_count >= 3:
            return "REJECT - HIGH PROBABILITY OF FALSE POSITIVE"
        elif score < 0.6 or red_flag_count >= 2:
            return "REVIEW REQUIRED - SUSPICIOUS PATTERNS DETECTED"
        elif score < 0.8 or red_flag_count >= 1:
            return "CAUTION - MINOR ISSUES DETECTED, MANUAL REVIEW RECOMMENDED"
        else:
            return "ACCEPT - ANALYSIS APPEARS LEGITIMATE"

    def print_validation_report(self, results: Dict[str, Any]) -> None:
        """Print a formatted validation report."""

        print("=" * 70)
        print("🔍 VULNERABILITY ANALYSIS VALIDATION REPORT")
        print("=" * 70)
        print(f"Report: {results['report_path']}")
        print(f"Status: {results['status']}")
        print(f"Validation Score: {results['validation_score']:.2f}/1.00")
        print(f"Recommendation: {results['recommendation']}")
        print()

        # Print validation checks
        print("📋 Validation Checks:")
        for check_name, passed in results['validation_checks'].items():
            status = "✅ PASS" if passed else "❌ FAIL"
            print(f"   {check_name.title()}: {status}")
        print()

        # Print red flags
        if results['red_flags']:
            print("🚩 RED FLAGS (Critical Issues):")
            for i, flag in enumerate(results['red_flags'], 1):
                print(f"   {i}. {flag}")
            print()

        # Print warnings
        if results['warnings']:
            print("⚠️  WARNINGS (Minor Issues):")
            for i, warning in enumerate(results['warnings'], 1):
                print(f"   {i}. {warning}")
            print()

        # Print recommendation explanation
        print("📝 RECOMMENDATION EXPLANATION:")
        score = results['validation_score']
        if score < 0.3:
            print("   The analysis shows multiple critical red flags indicating")
            print("   a high probability of fabricated or inaccurate reporting.")
        elif score < 0.6:
            print("   The analysis shows concerning patterns that require")
            print("   manual verification before acting on the findings.")
        elif score < 0.8:
            print("   The analysis is mostly reasonable but has some minor")
            print("   issues that should be reviewed for accuracy.")
        else:
            print("   The analysis appears legitimate with no major red flags.")

        print("=" * 70)


def main():
    """Main function for command-line usage."""

    if len(sys.argv) != 2:
        print("Usage: python3 quick_vulnerability_validator.py <path_to_vulnerability_report.json>")
        sys.exit(1)

    report_path = sys.argv[1]

    if not os.path.exists(report_path):
        print(f"❌ Error: File not found: {report_path}")
        sys.exit(1)

    validator = QuickVulnerabilityValidator()
    results = validator.validate_report(report_path)
    validator.print_validation_report(results)

    # Exit with appropriate code
    if "REJECT" in results["recommendation"]:
        sys.exit(2)  # Critical issues found
    elif "REVIEW" in results["recommendation"]:
        sys.exit(1)  # Suspicious patterns detected
    else:
        sys.exit(0)  # Looks legitimate


if __name__ == "__main__":
    main()